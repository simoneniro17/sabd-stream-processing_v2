services:
  gc-challenger:
    image: micro-challenger:latest
    container_name: LOCAL-CHALLENGER
    ports:
      - "8866:8866"
    volumes:
      - ./gc25-chall/data:/data
    command: ["0.0.0.0:8866", "/data"]
    networks:
      - sabd-stream-processing-network

  ### BROKER KAFKA ###
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - sabd-stream-processing-network

  kafka:
    image: confluentinc/cp-kafka:7.2.1
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 2097152
      KAFKA_REPLICA_FETCH_MAX_BYTES: 2097152
    depends_on:
      - zookeeper
    networks:
      - sabd-stream-processing-network

  ### PRODUCER E CONSUMER ###
  producer:
    build:
      context: .
      dockerfile: producer/Dockerfile
    container_name: producer
    depends_on:
      - kafka
      - gc-challenger
    volumes:
      - ./producer/app:/app
    command: ["python", "/app/producer.py", "--limit", "160"]
    #command: ["python", "/app/producer.py"]
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - sabd-stream-processing-network

  consumer:
    build:
      context: .
      dockerfile: consumer/Dockerfile
    container_name: consumer
    depends_on:
      - kafka
    volumes:
      - ./consumer/app:/app
      - ./results:/results
    command: ["tail", "-f", "/dev/null"]
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - sabd-stream-processing-network

  ### CLUSTER FLINK ###
  jobmanager:
    image: flink:2.0
    container_name: jobmanager
    ports:
      - "8081:8081"
      - "9249:9249"  # Porta per Prometheus
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: 0.0.0.0
        rest.port: 8081
        metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
        metrics.reporter.prom.port: 9249
    networks:
      - sabd-stream-processing-network

  taskmanager-1:
    image: flink:2.0
    container_name: taskmanager1
    ports:
      - "9250:9250"  # Porta per Prometheus del TaskManager 1
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
        metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
        metrics.reporter.prom.port: 9250
    networks:
      - sabd-stream-processing-network

  taskmanager-2:
    image: flink:2.0
    container_name: taskmanager2
    ports:
      - "9251:9251"  # Porta per Prometheus del TaskManager 2
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
        metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
        metrics.reporter.prom.port: 9251
    networks:
      - sabd-stream-processing-network

  flink-client:
    image: flink:2.0
    container_name: flink-client
    depends_on:
      - jobmanager
      - taskmanager-1
      - taskmanager-2
    volumes:
      - ./flink/jobs:/opt/flink/jobs
    command: >
      flink run --jobmanager jobmanager:8081 -c it.flink.StreamingJob /opt/flink/jobs/flink-1.0-SNAPSHOT.jar
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager
        rest.port: 8081
    networks:
      - sabd-stream-processing-network

  ### KAFKA STREAMS ###
  kafka-streams:
    build:
      context: ./kafkastreams
      dockerfile: Dockerfile
    container_name: kafka-streams
    depends_on:
      - kafka
    volumes:
      - ./kafkastreams/target/kafkastreams-1.0-SNAPSHOT-jar-with-dependencies.jar:/app/jobs/app.jar
    command: ["java", "-jar", "/app/jobs/app.jar"]  
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - sabd-stream-processing-network

  ### MONITORING E VISUALIZATION ###
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    tty: true
    networks:
      - sabd-stream-processing-network

  grafana:
    image: grafana/grafana:12.0.0
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/dashboard-definitions:/var/lib/grafana/dashboards
    tty: true
    networks:
      - sabd-stream-processing-network

networks:
  sabd-stream-processing-network:
    driver: bridge